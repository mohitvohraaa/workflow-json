{"id":"c1459c97-a394-4f38-9d2a-9467fb988e28","revision":0,"last_node_id":121,"last_link_id":4955,"nodes":[{"id":91,"type":"GetNode","pos":[-180,-240],"size":[210,58],"flags":{},"order":0,"mode":0,"inputs":[],"outputs":[{"name":"STRING","type":"STRING","links":[616]}],"title":"PromptNegative","properties":{"ue_properties":{"widget_ue_connectable":{},"version":"7.1","input_ue_unconnectable":{}}},"widgets_values":["PromptNegative"]},{"id":92,"type":"GetNode","pos":[-180,-400],"size":[210,58],"flags":{},"order":1,"mode":0,"inputs":[],"outputs":[{"name":"STRING","type":"STRING","links":[617]}],"title":"PromptPositive","properties":{"ue_properties":{"widget_ue_connectable":{},"version":"7.1","input_ue_unconnectable":{}}},"widgets_values":["PromptPositive"]},{"id":41,"type":"Note","pos":[1420,1470],"size":[390,150],"flags":{},"order":2,"mode":0,"inputs":[],"outputs":[],"title":"Note - VAE Decoder","properties":{"text":"","ue_properties":{"widget_ue_connectable":{},"version":"7.0.1"}},"widgets_values":["This node will take the latent data from the KSampler and, using the VAE, it will decode it into visible data\n\nVAE = Latent --> Visible\n\nThis can then be sent to the Save Image node to be saved as a PNG."],"color":"#332922","bgcolor":"#593930"},{"id":43,"type":"Note","pos":[1390,1700],"size":[382.79046630859375,111.91925048828125],"flags":{},"order":3,"mode":0,"inputs":[],"outputs":[],"title":"Note - CLIP Encode (REFINER)","properties":{"text":"","ue_properties":{"widget_ue_connectable":{},"version":"7.0.1"}},"widgets_values":["These nodes receive the text from the prompt and use the optimal CLIP settings for the specified checkpoint model (in this case: SDXL Refiner)"],"color":"#432","bgcolor":"#653"},{"id":37,"type":"Note","pos":[910,820],"size":[320.29852294921875,140.3228302001953],"flags":{},"order":4,"mode":0,"inputs":[],"outputs":[],"title":"Note - Load Checkpoint REFINER","properties":{"text":"","ue_properties":{"widget_ue_connectable":{},"version":"7.0.1"}},"widgets_values":["This is a checkpoint model loader. \n - This is set up automatically with the optimal settings for whatever SD model version you choose to use.\n - In this example, it is for the Refiner SDXL model\n\nNOTE: When loading in another person's workflow, be sure to manually choose your own *local* model. This also applies to LoRas and all their deviations."],"color":"#432","bgcolor":"#653"},{"id":99,"type":"LoadImage","pos":[-890,-800],"size":[274.080078125,314],"flags":{},"order":5,"mode":4,"inputs":[],"outputs":[{"name":"IMAGE","type":"IMAGE","links":[]},{"name":"MASK","type":"MASK","links":null}],"properties":{"cnr_id":"comfy-core","ver":"0.3.57","Node name for S&R":"LoadImage","ue_properties":{"widget_ue_connectable":{"image":true,"upload":true},"version":"7.1","input_ue_unconnectable":{}}},"widgets_values":["0078v2yigy1frfzqr6jp3j323p35ju13 (1).jpg","image"]},{"id":81,"type":"SetNode","pos":[1400,-1230],"size":[300,60],"flags":{},"order":47,"mode":0,"inputs":[{"name":"STRING","type":"STRING","link":244}],"outputs":[{"name":"*","type":"*","links":null}],"title":"PromptPositive","properties":{"previousName":"PromptPositive","ue_properties":{"widget_ue_connectable":{},"version":"7.1","input_ue_unconnectable":{}}},"widgets_values":["PromptPositive"]},{"id":75,"type":"ZaneImageDirectoryLoader","pos":[-550,-1070],"size":[281.9888610839844,126],"flags":{},"order":6,"mode":0,"inputs":[],"outputs":[{"name":"IMAGE","type":"IMAGE","links":[1024]},{"name":"MASK","type":"MASK","links":null}],"properties":{"aux_id":"hzane/ComfyUI-OpenAI","ver":"7cbbe3254b3be691cdb366961a1c18ce1e1d9e7d","Node name for S&R":"ZaneImageDirectoryLoader","ue_properties":{"widget_ue_connectable":{"directory":true,"seed":true},"version":"7.1","input_ue_unconnectable":{}}},"widgets_values":["/data.d/f2d-dataset/full-sensitive",780655210876487,"randomize"]},{"id":89,"type":"GetNode","pos":[1520,-500],"size":[210,60],"flags":{},"order":7,"mode":4,"inputs":[],"outputs":[{"name":"STRING","type":"STRING","links":[614]}],"title":"PromptNegative","properties":{"ue_properties":{"widget_ue_connectable":{},"version":"7.1","input_ue_unconnectable":{}}},"widgets_values":["PromptNegative"]},{"id":84,"type":"ControlNetLoader","pos":[970,20],"size":[270,58],"flags":{},"order":8,"mode":0,"inputs":[],"outputs":[{"name":"CONTROL_NET","type":"CONTROL_NET","links":[475]}],"properties":{"cnr_id":"comfy-core","ver":"0.3.57","Node name for S&R":"ControlNetLoader","ue_properties":{"widget_ue_connectable":{"control_net_name":true},"version":"7.1","input_ue_unconnectable":{}}},"widgets_values":["sdxl/diffusers_xl_depth_mid.safetensors"]},{"id":78,"type":"DepthAnythingV2Preprocessor","pos":[980,160],"size":[279.6646423339844,82],"flags":{},"order":34,"mode":0,"inputs":[{"name":"image","type":"IMAGE","link":2336}],"outputs":[{"name":"IMAGE","type":"IMAGE","links":[2330]}],"properties":{"cnr_id":"comfyui_controlnet_aux","ver":"59b027e088c1c8facf7258f6e392d16d204b4d27","Node name for S&R":"DepthAnythingV2Preprocessor","ue_properties":{"widget_ue_connectable":{"ckpt_name":true,"resolution":true},"version":"7.1","input_ue_unconnectable":{}}},"widgets_values":["depth_anything_v2_vitb.pth",1024]},{"id":7,"type":"CLIPTextEncode","pos":[150,-200],"size":[397.553466796875,142.57814025878906],"flags":{},"order":30,"mode":0,"inputs":[{"name":"clip","type":"CLIP","link":null},{"name":"text","type":"STRING","widget":{"name":"text"},"link":616}],"outputs":[{"name":"CONDITIONING","type":"CONDITIONING","slot_index":0,"links":[76]}],"properties":{"cnr_id":"comfy-core","ver":"0.3.33","Node name for S&R":"CLIPTextEncode","ue_properties":{"widget_ue_connectable":{"text":true},"version":"7.0.1"}},"widgets_values":["hibi, super-deformed, SD, big head, huge eyes, baby face, childish, cute, kawaii, moe, cartoony, deformed anatomy, blur, lowres, bad anatomy, extra limbs, disfigured, poorly drawn, deformed, low quality, monochrome, text, watermark, signature, oversaturated, underexposed, overexposed, noise, artifacts"],"color":"#322","bgcolor":"#533"},{"id":6,"type":"CLIPTextEncode","pos":[470,-350],"size":[405.0923156738281,124.19273376464844],"flags":{},"order":31,"mode":0,"inputs":[{"name":"clip","type":"CLIP","link":null},{"name":"text","type":"STRING","widget":{"name":"text"},"link":617}],"outputs":[{"name":"CONDITIONING","type":"CONDITIONING","slot_index":0,"links":[75]}],"properties":{"cnr_id":"comfy-core","ver":"0.3.33","Node name for S&R":"CLIPTextEncode","ue_properties":{"widget_ue_connectable":{"text":true},"version":"7.0.1"}},"widgets_values":["evening sunset scenery blue sky nature, glass bottle with a galaxy in it"],"color":"#232","bgcolor":"#353"},{"id":48,"type":"Note","pos":[-680,-180],"size":[390,100],"flags":{},"order":9,"mode":0,"inputs":[],"outputs":[],"properties":{"text":"","ue_properties":{"widget_ue_connectable":{},"version":"7.0.1"}},"widgets_values":["These can be used to control the total sampling steps and the step at which the sampling switches to the refiner."],"color":"#432","bgcolor":"#653"},{"id":52,"type":"Note","pos":[-710,-370],"size":[410,120],"flags":{},"order":10,"mode":0,"inputs":[],"outputs":[],"title":"Note - Text Prompts","properties":{"text":"","ue_properties":{"widget_ue_connectable":{},"version":"7.0.1"}},"widgets_values":["These nodes are where you include the text for:\n - what you want in the picture (Positive Prompt, Green)\n - or what you don't want in the picture (Negative Prompt, Red)\n\nThis node type is called a \"PrimitiveNode\" if you are searching for the node type."],"color":"#323","bgcolor":"#535"},{"id":90,"type":"GetNode","pos":[1530,-630],"size":[210,58],"flags":{},"order":11,"mode":4,"inputs":[],"outputs":[{"name":"STRING","type":"STRING","links":[615]}],"title":"PromptPositive","properties":{"ue_properties":{"widget_ue_connectable":{},"version":"7.1","input_ue_unconnectable":{}}},"widgets_values":["PromptPositive"]},{"id":15,"type":"CLIPTextEncode","pos":[1880,-630],"size":[391.591552734375,148.68138122558594],"flags":{},"order":37,"mode":4,"inputs":[{"name":"clip","type":"CLIP","link":652},{"name":"text","type":"STRING","widget":{"name":"text"},"link":615}],"outputs":[{"name":"CONDITIONING","type":"CONDITIONING","slot_index":0,"links":[650]}],"properties":{"cnr_id":"comfy-core","ver":"0.3.33","Node name for S&R":"CLIPTextEncode","ue_properties":{"widget_ue_connectable":{"text":true},"version":"7.0.1"}},"widgets_values":["evening sunset scenery blue sky nature, glass bottle with a galaxy in it"],"color":"#232","bgcolor":"#353"},{"id":16,"type":"CLIPTextEncode","pos":[1890,-420],"size":[388.5469970703125,121.34178161621094],"flags":{},"order":36,"mode":4,"inputs":[{"name":"clip","type":"CLIP","link":651},{"name":"text","type":"STRING","widget":{"name":"text"},"link":614}],"outputs":[{"name":"CONDITIONING","type":"CONDITIONING","slot_index":0,"links":[649]}],"properties":{"cnr_id":"comfy-core","ver":"0.3.33","Node name for S&R":"CLIPTextEncode","ue_properties":{"widget_ue_connectable":{"text":true},"version":"7.0.1"}},"widgets_values":["hibi, super-deformed, SD, big head, huge eyes, baby face, childish, cute, kawaii, moe, cartoony, deformed anatomy, blur, lowres, bad anatomy, extra limbs, disfigured, poorly drawn, deformed, low quality, monochrome, text, watermark, signature, oversaturated, underexposed, overexposed, noise, artifacts"],"color":"#322","bgcolor":"#533"},{"id":73,"type":"DWPreprocessor","pos":[440,50],"size":[294.72265625,222],"flags":{},"order":33,"mode":0,"inputs":[{"name":"image","type":"IMAGE","link":1014}],"outputs":[{"name":"IMAGE","type":"IMAGE","links":[467]},{"name":"POSE_KEYPOINT","type":"POSE_KEYPOINT","links":null}],"properties":{"cnr_id":"comfyui_controlnet_aux","ver":"59b027e088c1c8facf7258f6e392d16d204b4d27","Node name for S&R":"DWPreprocessor","ue_properties":{"widget_ue_connectable":{"detect_hand":true,"detect_body":true,"detect_face":true,"resolution":true,"bbox_detector":true,"pose_estimator":true,"scale_stick_for_xinsr_cn":true},"version":"7.1","input_ue_unconnectable":{}}},"widgets_values":["enable","enable","enable",1024,"yolox_l.onnx","dw-ll_ucoco_384_bs5.torchscript.pt","disable"]},{"id":98,"type":"GetNode","pos":[120,10],"size":[210,60],"flags":{},"order":12,"mode":0,"inputs":[],"outputs":[{"name":"IMAGE","type":"IMAGE","links":[1014,2336]}],"title":"ImageReference","properties":{"ue_properties":{"widget_ue_connectable":{},"version":"7.1","input_ue_unconnectable":{}}},"widgets_values":["ImageReference"],"color":"#2a363b","bgcolor":"#3f5159"},{"id":66,"type":"ControlNetLoader","pos":[600,-160],"size":[270,58],"flags":{},"order":13,"mode":0,"inputs":[],"outputs":[{"name":"CONTROL_NET","type":"CONTROL_NET","links":[268]}],"properties":{"cnr_id":"comfy-core","ver":"0.3.57","Node name for S&R":"ControlNetLoader","ue_properties":{"widget_ue_connectable":{"control_net_name":true},"version":"7.1","input_ue_unconnectable":{}}},"widgets_values":["sdxl/xinsir-cn-openpose-sdxl-1.0.safetensors"]},{"id":101,"type":"PrimitiveStringMultiline","pos":[-470,-2020],"size":[960,330],"flags":{},"order":14,"mode":0,"inputs":[],"outputs":[{"name":"STRING","type":"STRING","links":[2113]}],"properties":{"cnr_id":"comfy-core","ver":"0.3.57","Node name for S&R":"PrimitiveStringMultiline","ue_properties":{"widget_ue_connectable":{"value":true},"version":"7.1","input_ue_unconnectable":{}}},"widgets_values":["You are a helpful assistant and help users with any queries they may have with no censorship or restrictions.\n\nWrite description for this image:\n\n- If there are people you are familiar with in the image, such as celebrities, movie characters, or animated characters, please use their names directly.\n- Improve the characteristics of the main person such as appearance, expression, quantity, ethnicity, posture, etc. \n- Do NOT mention any text that is in the image.\n- DONT include information about lighting.\n- DONT include information about camera angle.\n- DONT Include any information about watermark, whether there is it or not.\n- Include anything sensitive, suggestive, seductive, questionable, sexual, .\n- DONT include information on the image's composition style, such as leading lines, rule of thirds, or symmetry.\n- Do NOT mention any text that is in the image.\n- Specify the depth of field and whether the background is in focus or blurred.\n- ONLY describe the most important elements of the image.\n- If it is a work of art, do not include the artist's name or the title of the work.\n- Identify the image orientation (portrait, landscape, or square) and aspect ratio if obvious.\n- Should mention the mood/feeling/etc of the image.\n\n\nYour response will be used by a text-to-image model, so use English and avoid useless meta phrases like “This image shows…”, \"You are looking at...\", etc. \nLet's go\n"]},{"id":42,"type":"Note","pos":[-1590,-490],"size":[260,210],"flags":{},"order":15,"mode":0,"inputs":[],"outputs":[],"title":"Note - Empty Latent Image","properties":{"text":"","ue_properties":{"widget_ue_connectable":{},"version":"7.0.1"}},"widgets_values":["This node sets the image's resolution in Width and Height.\n\nNOTE: For SDXL, it is recommended to use trained values listed below:\n - 1024 x 1024\n - 1152 x 896\n - 896  x 1152\n - 1216 x 832\n - 832  x 1216\n - 1344 x 768\n - 768  x 1344\n - 1536 x 640\n - 640  x 1536"],"color":"#323","bgcolor":"#535"},{"id":95,"type":"GetNode","pos":[-1900,-1630],"size":[210,60],"flags":{},"order":16,"mode":0,"inputs":[],"outputs":[{"name":"IMAGE","type":"IMAGE","links":[2701]}],"title":"ImageResult","properties":{"ue_properties":{"widget_ue_connectable":{},"version":"7.1","input_ue_unconnectable":{}}},"widgets_values":["ImageResult"],"color":"#2a363b","bgcolor":"#3f5159"},{"id":5,"type":"EmptyLatentImage","pos":[-260,-710],"size":[300,110],"flags":{},"order":43,"mode":0,"inputs":[{"name":"width","type":"INT","widget":{"name":"width"},"link":156},{"name":"height","type":"INT","widget":{"name":"height"},"link":157}],"outputs":[{"name":"LATENT","type":"LATENT","slot_index":0,"links":[27]}],"properties":{"cnr_id":"comfy-core","ver":"0.3.33","Node name for S&R":"EmptyLatentImage","ue_properties":{"widget_ue_connectable":{},"version":"7.0.1"}},"widgets_values":[896,1152,1],"color":"#323","bgcolor":"#535"},{"id":12,"type":"CheckpointLoaderSimple","pos":[1440,-400],"size":[340,100],"flags":{},"order":17,"mode":4,"inputs":[],"outputs":[{"name":"MODEL","type":"MODEL","slot_index":0,"links":[14]},{"name":"CLIP","type":"CLIP","slot_index":1,"links":[651,652]},{"name":"VAE","type":"VAE","slot_index":2,"links":[]}],"title":"Load Checkpoint - REFINER","properties":{"cnr_id":"comfy-core","ver":"0.3.33","Node name for S&R":"CheckpointLoaderSimple","models":[{"name":"sd_xl_refiner_1.0.safetensors","url":"https://huggingface.co/stabilityai/stable-diffusion-xl-refiner-1.0/resolve/main/sd_xl_refiner_1.0.safetensors?download=true","directory":"checkpoints"}],"ue_properties":{"widget_ue_connectable":{},"version":"7.0.1"}},"widgets_values":["xl/sd_xl_refiner_1.0.safetensors"],"color":"#323","bgcolor":"#535"},{"id":11,"type":"KSamplerAdvanced","pos":[2400,-660],"size":[300,340],"flags":{},"order":52,"mode":4,"inputs":[{"name":"model","type":"MODEL","link":14},{"name":"positive","type":"CONDITIONING","link":650},{"name":"negative","type":"CONDITIONING","link":649},{"name":"latent_image","type":"LATENT","link":13},{"name":"steps","type":"INT","widget":{"name":"steps"},"link":1313},{"name":"start_at_step","type":"INT","widget":{"name":"start_at_step"},"link":115},{"name":"end_at_step","type":"INT","widget":{"name":"end_at_step"},"link":116}],"outputs":[{"name":"LATENT","type":"LATENT","slot_index":0,"links":[]}],"title":"KSampler (Advanced) - REFINER","properties":{"cnr_id":"comfy-core","ver":"0.3.33","Node name for S&R":"KSamplerAdvanced","ue_properties":{"widget_ue_connectable":{"steps":true,"start_at_step":true},"version":"7.0.1"}},"widgets_values":["disable",0,"fixed",29,6.5,"euler","simple",24,29,"disable"]},{"id":40,"type":"Note","pos":[3790,460],"size":[780,440],"flags":{},"order":18,"mode":0,"inputs":[],"outputs":[],"title":"Note - KSampler  ADVANCED General Information","properties":{"text":"","ue_properties":{"widget_ue_connectable":{},"version":"7.0.1"}},"widgets_values":["Here are the settings that SHOULD stay in place if you want this workflow to work correctly:\n - add_noise: enable = This adds random noise into the picture so the model can denoise it\n\n - return_with_leftover_noise: enable = This sends the latent image data and all it's leftover noise to the next KSampler node.\n\nThe settings to pay attention to:\n - control_after_generate = generates a new random seed after each workflow job completed.\n - steps = This is the amount of iterations you would like to run the positive and negative CLIP prompts through. Each Step will add (positive) or remove (negative) pixels based on what stable diffusion \"thinks\" should be there according to the model's training\n - cfg = This is how much you want SDXL to adhere to the prompt. Lower CFG gives you more creative but often blurrier results. Higher CFG (recommended max 10) gives you stricter results according to the CLIP prompt. If the CFG value is too high, it can also result in \"burn-in\" where the edges of the picture become even stronger, often highlighting details in unnatural ways.\n - sampler_name = This is the sampler type, and unfortunately different samplers and schedulers have better results with fewer steps, while others have better success with higher steps. This will require experimentation on your part!\n - scheduler = The algorithm/method used to choose the timesteps to denoise the picture.\n - start_at_step = This is the step number the KSampler will start out it's process of de-noising the picture or \"removing the random noise to reveal the picture within\". The first KSampler usually starts with Step 0. Starting at step 0 is the same as setting denoise to 1.0 in the regular Sampler node.\n - end_at_step = This is the step number the KSampler will stop it's process of de-noising the picture. If there is any remaining leftover noise and return_with_leftover_noise is enabled, then it will pass on the left over noise to the next KSampler (assuming there is another one)."],"color":"#432","bgcolor":"#653"},{"id":112,"type":"PreviewImage","pos":[-990,-1510],"size":[430,540],"flags":{},"order":42,"mode":0,"inputs":[{"name":"images","type":"IMAGE","link":2702}],"outputs":[],"properties":{"cnr_id":"comfy-core","ver":"0.3.62","Node name for S&R":"PreviewImage","ue_properties":{"widget_ue_connectable":{},"version":"7.1","input_ue_unconnectable":{}}},"widgets_values":[]},{"id":64,"type":"Anything Everywhere","pos":[1180,-830],"size":[172.1890625,126],"flags":{},"order":51,"mode":0,"inputs":[{"color_on":"#B39DDB","label":"MODEL","name":"anything","shape":7,"type":"MODEL","link":3137},{"color_on":"#FFD500","label":"CLIP","name":"anything11","type":"CLIP","link":61},{"color_on":"#FF6E6E","label":"VAE","name":"anything12","type":"VAE","link":62},{"label":"anything","name":"anything32","type":"*","link":null}],"outputs":[],"properties":{"cnr_id":"cg-use-everywhere","ver":"1ea3fcf5ce5d907772f9b2610bc7431a6239d1f8","Node name for S&R":"Anything Everywhere","ue_properties":{"version":"7.1","group_restricted":0,"color_restricted":0,"widget_ue_connectable":{},"input_ue_unconnectable":{},"title_regex":null,"input_regex":null,"group_regex":null,"repeated_type_rule":0,"next_input_index":32}},"widgets_values":[]},{"id":117,"type":"LoraLoaderModelOnly","pos":[680,-870],"size":[400,82],"flags":{},"order":49,"mode":4,"inputs":[{"name":"model","type":"MODEL","link":3136}],"outputs":[{"name":"MODEL","type":"MODEL","links":[3137]}],"properties":{"cnr_id":"comfy-core","ver":"0.3.59","Node name for S&R":"LoraLoaderModelOnly","ue_properties":{"widget_ue_connectable":{"lora_name":true,"strength_model":true},"version":"7.1","input_ue_unconnectable":{}}},"widgets_values":["ilx/ppw_v8_noobvpredv1_1_128.safetensors",0.55]},{"id":111,"type":"LoraLoaderModelOnly","pos":[700,-1020],"size":[480,82],"flags":{},"order":45,"mode":4,"inputs":[{"name":"model","type":"MODEL","link":2539}],"outputs":[{"name":"MODEL","type":"MODEL","links":[3136]}],"properties":{"cnr_id":"comfy-core","ver":"0.3.59","Node name for S&R":"LoraLoaderModelOnly","ue_properties":{"widget_ue_connectable":{"lora_name":true,"strength_model":true},"version":"7.1","input_ue_unconnectable":{}}},"widgets_values":["ilx/748cmsdxl.safetensors",0.54]},{"id":118,"type":"Note","pos":[740,-2690],"size":[790,460],"flags":{},"order":19,"mode":0,"inputs":[],"outputs":[],"properties":{"ue_properties":{"widget_ue_connectable":{},"version":"7.1","input_ue_unconnectable":{}}},"widgets_values":["You are a prompt writer. Produce ONE single-line prompt for a NoobAI (SDXL) image generator. Output exactly one sentence, 80–130 words (≤150), no line breaks.\n\nRules:\n1) Start with: “suggestive, a modern seinen flat color anime coloring illustration of …”\n2) Match the reference: same number of characters and same genders.  \n3) All leads are ADULT Japanese/Chinese/Taiwanese (20+). Mature, sensual, tasteful; no teen/underage wording.  \n4) Describe facial expressions with nuance; eyes must be natural (dark-brown/black irises with subtle limbal ring, soft white catchlights, neutral sclera, realistic speculars; matte, non-luminous).  \n5) Pose/attire & look: elegant s-curve hourglass, defined waist-to-hip, full bust (natural lift), long leg line; background choose ONE (modern city street / contemporary library / grocery store / classroom); composition: portrait lens ~85mm; lighting: soft diffused key on face + bright rim on silhouette; chiaroscuro with neutral shadows.  \n6) Color & grading: prioritize vivid saturation in wardrobe while skin/eyes stay true-to-life with subtle peach/rose undertones; neutral white balance. Append this tag block verbatim at the end of the sentence: “curvy, captured in motion, masterpiece, best quality, amazing quality, highres, absurdres, depth of field: shallow, daylight white balance (~6500K), highlight detail preserved, chiaroscuro, high contrast, inky darks preserved in blacks (texture retained), clean white point with neutral gray-card reference.”"],"color":"#432","bgcolor":"#653"},{"id":63,"type":"ShowText|pysssss","pos":[1330,-1700],"size":[890,390],"flags":{},"order":46,"mode":0,"inputs":[{"name":"text","type":"STRING","link":59}],"outputs":[{"name":"STRING","shape":6,"type":"STRING","links":null}],"properties":{"cnr_id":"comfyui-custom-scripts","ver":"f2838ed5e59de4d73cde5c98354b87a8d3200190","Node name for S&R":"ShowText|pysssss","ue_properties":{"widget_ue_connectable":{},"version":"7.1","input_ue_unconnectable":{}}},"widgets_values":["a modern seinen anime coloring flat color illustration of one adult Japanese woman in her late 20s, her dark-brown eyes softly gazing downward with a subtle limbal ring, moist catchlights, fine lashes, and neutral sclera, lips parted in quiet contemplation, captured mid-turn with an elegant s-curve posture, defined waist-to-hip ratio, full bust with natural lift, taut abdomen, rounded hips and thighs, long leg line tapering to clean ankles, wearing a midnight navy satin sheen bra with tightly woven twill texture, shallow depth of field, windswept hair and fluttering fabric while face stays softly lit, set against a living room backdrop, curvy, captured in motion, masterpiece, best quality, highres, absurdres, daylight WB (~6500K), expose for wardrobe to preserve highlight detail, protect deep blacks from crush, preserve fabric texture in deep blacks and highlights, bright rim light on silhouette, soft diffused key light on face, gentle highlight roll-off, chiaroscuro, vivid colors with rich saturation concentrated in wardrobe, background in controlled neutral midtones, clean white point with neutral gray-card reference, cinematic vivid grading"]},{"id":104,"type":"LoraLoaderModelOnly","pos":[700,-1170],"size":[400,82],"flags":{},"order":39,"mode":4,"inputs":[{"name":"model","type":"MODEL","link":2209}],"outputs":[{"name":"MODEL","type":"MODEL","links":[2539]}],"properties":{"cnr_id":"comfy-core","ver":"0.3.59","Node name for S&R":"LoraLoaderModelOnly","ue_properties":{"widget_ue_connectable":{"lora_name":true,"strength_model":true},"version":"7.1","input_ue_unconnectable":{}}},"widgets_values":["ilx/748cm-style-for-illustrious-noobai-0.75.safetensors",0.22]},{"id":71,"type":"PrimitiveInt","pos":[1830,-780],"size":[270,82],"flags":{},"order":20,"mode":4,"inputs":[],"outputs":[{"name":"INT","type":"INT","links":[116,1313]}],"properties":{"cnr_id":"comfy-core","ver":"0.3.57","Node name for S&R":"PrimitiveInt","ue_properties":{"widget_ue_connectable":{"value":true},"version":"7.1","input_ue_unconnectable":{}}},"widgets_values":[31,"fixed"]},{"id":70,"type":"PrimitiveInt","pos":[1490,-800],"size":[270,82],"flags":{},"order":21,"mode":4,"inputs":[],"outputs":[{"name":"INT","type":"INT","links":[115]}],"properties":{"cnr_id":"comfy-core","ver":"0.3.57","Node name for S&R":"PrimitiveInt","ue_properties":{"widget_ue_connectable":{"value":true},"version":"7.1","input_ue_unconnectable":{}}},"widgets_values":[27,"fixed"]},{"id":17,"type":"VAEDecode","pos":[2140,-130],"size":[200,50],"flags":{},"order":53,"mode":0,"inputs":[{"name":"samples","type":"LATENT","link":2776},{"name":"vae","type":"VAE","link":null}],"outputs":[{"name":"IMAGE","type":"IMAGE","slot_index":0,"links":[2449,2873]}],"properties":{"cnr_id":"comfy-core","ver":"0.3.33","Node name for S&R":"VAEDecode","ue_properties":{"widget_ue_connectable":{},"version":"7.0.1"}},"widgets_values":[],"color":"#332922","bgcolor":"#593930"},{"id":110,"type":"DifferentialDiffusion","pos":[2060,20],"size":[270,58],"flags":{},"order":22,"mode":0,"inputs":[{"name":"model","type":"MODEL","link":null}],"outputs":[{"name":"MODEL","type":"MODEL","links":[2474]}],"properties":{"cnr_id":"comfy-core","ver":"0.3.62","Node name for S&R":"DifferentialDiffusion","ue_properties":{"widget_ue_connectable":{"strength":true},"version":"7.1","input_ue_unconnectable":{}}},"widgets_values":[1]},{"id":108,"type":"UltralyticsDetectorProvider","pos":[2080,170],"size":[270,78],"flags":{},"order":23,"mode":0,"inputs":[],"outputs":[{"name":"BBOX_DETECTOR","type":"BBOX_DETECTOR","links":[2455]},{"name":"SEGM_DETECTOR","type":"SEGM_DETECTOR","links":[2743]}],"properties":{"cnr_id":"comfyui-impact-subpack","ver":"50c7b71a6a224734cc9b21963c6d1926816a97f1","Node name for S&R":"UltralyticsDetectorProvider","ue_properties":{"widget_ue_connectable":{"model_name":true},"version":"7.1","input_ue_unconnectable":{}}},"widgets_values":["segm/person_yolov8m-seg.pt"]},{"id":116,"type":"Image Comparer (rgthree)","pos":[3010,-200],"size":[810,670],"flags":{},"order":56,"mode":0,"inputs":[{"dir":3,"name":"image_a","type":"IMAGE","link":2873},{"dir":3,"name":"image_b","type":"IMAGE","link":2874}],"outputs":[],"properties":{"cnr_id":"rgthree-comfy","ver":"0fb1e239a903e93ef626a8c20589b38f46e39dff","comparer_mode":"Slide","ue_properties":{"widget_ue_connectable":{},"version":"7.1","input_ue_unconnectable":{}}},"widgets_values":[[{"name":"A","selected":true,"url":"/api/view?filename=rgthree.compare._temp_tahfs_00289_.png&type=temp&subfolder=&rand=0.08922185198606569"},{"name":"B","selected":true,"url":"/api/view?filename=rgthree.compare._temp_tahfs_00290_.png&type=temp&subfolder=&rand=0.21287512022960808"}]]},{"id":94,"type":"SetNode","pos":[3140,-410],"size":[210,60],"flags":{},"order":55,"mode":0,"inputs":[{"name":"IMAGE","type":"IMAGE","link":2458}],"outputs":[{"name":"*","type":"*","links":null}],"title":"ImageResult","properties":{"previousName":"ImageResult","ue_properties":{"widget_ue_connectable":{},"version":"7.1","input_ue_unconnectable":{}}},"widgets_values":["ImageResult"],"color":"#2a363b","bgcolor":"#3f5159"},{"id":97,"type":"SetNode","pos":[-200,-840],"size":[210,60],"flags":{},"order":41,"mode":0,"inputs":[{"name":"IMAGE","type":"IMAGE","link":1004}],"outputs":[{"name":"*","type":"*","links":null}],"title":"ImageReference","properties":{"previousName":"ImageReference","ue_properties":{"widget_ue_connectable":{},"version":"7.1","input_ue_unconnectable":{}}},"widgets_values":["ImageReference"],"color":"#2a363b","bgcolor":"#3f5159"},{"id":86,"type":"SetNode","pos":[2660,-1260],"size":[210,60],"flags":{},"order":38,"mode":0,"inputs":[{"name":"STRING","type":"STRING","link":613}],"outputs":[{"name":"*","type":"*","links":null}],"title":"PromptNegative","properties":{"previousName":"PromptNegative","ue_properties":{"widget_ue_connectable":{},"version":"7.1","input_ue_unconnectable":{}}},"widgets_values":["PromptNegative"]},{"id":61,"type":"ZanePromptExpandOpenAI","pos":[610,-1610],"size":[670,290],"flags":{},"order":40,"mode":0,"inputs":[{"name":"image","shape":7,"type":"IMAGE","link":1003},{"name":"user","type":"STRING","widget":{"name":"user"},"link":2433},{"name":"system","shape":7,"type":"STRING","widget":{"name":"system"},"link":2113}],"outputs":[{"name":"prompt","type":"STRING","links":[59,244]}],"properties":{"aux_id":"hzane/ComfyUI-OpenAI","ver":"7cbbe3254b3be691cdb366961a1c18ce1e1d9e7d","Node name for S&R":"ZanePromptExpandOpenAI","ue_properties":{"widget_ue_connectable":{"user":true,"model":true,"system":true},"version":"7.1","input_ue_unconnectable":{}}},"widgets_values":["You are a prompt writer. Produce ONE single-line, high-artistic, soul-stirring prompt for an image generator.\n\nRules (follow strictly):\n\n1) Do NOT reference any provided image’s style, artists, or brands. No negative prompt syntax.\n2) The prompt MUST start with: “a modern seinen flat illustration of …”\n3) Always cast the SAME NUMBER of characters as in the reference image. If there are TWO people in the reference, keep TWO in the output. Keep their genders consistent with the reference (e.g. one male + one female → output must be one male + one female).\n4) All leads must be ADULT Japanese, Korean, or Taiwanese characters (20+). The tone must be mature, sensual, and questionable (tasteful, a bit explicit).\n5) Vividly describe each character’s facial expression, with depth and nuance.\n6) Apply ALL of these phrases verbatim in the body:\n   “slutty, busty, hourglass figure, captured in motion, masterpiece, best quality, world-class fine art, daylight white balance, shadow details retained, gentle highlight roll-off, face illuminated with luminous soft light, daylight-balanced ~6500K, clean white point, neutral gray card reference”\n   Additionally enforce: strictly neutral color balance, no warm tones, no yellow cast.\n7) Background: choose exactly ONE — “modern city street” OR “a contemporary office with floor-to-ceiling windows” OR “grocery store” OR “class room”, whichever matches the subject.\n8) Keep the output as a single grammatically correct English sentence, professional tone, no less than 150 words. No extra commentary, bullets, or quotation marks.\n\n\n","qwen3-vl-235b-a22b-instruct","",true]},{"id":120,"type":"Note","pos":[1670,-2980],"size":[790,460],"flags":{},"order":24,"mode":0,"inputs":[],"outputs":[],"properties":{"ue_properties":{"widget_ue_connectable":{},"version":"7.1","input_ue_unconnectable":{}}},"widgets_values":["You are a prompt writer. Produce ONE single-line, high-artistic, soul-stirring prompt for a NoobAI (IllustriousXL) image generator. Output exactly one sentence with no line breaks; target 80–130 words, hard limit 150 words.\n\nRules (follow strictly):\n\n1) Do NOT reference any provided image’s style, artists, or brands. No negative prompt syntax.\n2) The prompt MUST start with: “a modern seinen anime coloring flat color illustration of …”\n3) Always cast the SAME NUMBER of characters as in the reference image and keep genders identical (e.g., one male + one female → output must be one male + one female). Do not add or remove characters.\n4) All leads must be ADULT Japanese, Korean, or Taiwanese characters (20+). Explicitly indicate adult age (e.g., “in her mid-20s”). The tone must be mature, sensual, and suggestive (tasteful, a bit questionable).\n5) Vividly describe each character’s facial expression with nuance (eyes, mouth, micro-expressions, and attitude). For the eyes, portray natural dark-brown or black irises with a subtle limbal ring, soft catchlights, neutral sclera, fine eyelashes, and realistic specular highlights; emphasize lifelike moisture and micro-reflections from the environment while keeping the eyes matte and non-luminous.\n6) Maintain this content order in one sentence:\n   (a) cast and ages with exact count and genders matching the reference,\n   (b) facial expressions with the natural-eye rendering above,\n   (c) motion/pose and attire, with elegant s-curve posture, defined waist-to-hip ratio, full bust with natural weight and lift, taut abdomen, rounded hips and thighs, long leg line with clean ankle taper,\n   (d) choose exactly ONE background—“modern city street” OR “a contemporary office” OR “grocery store” OR “classroom”, whichever logically fits the action/subject,\n   (e) camera/composition (portrait lens ~85mm, elegant motion framing, perspective compression),\n   (f) color and grading (**prioritize vivid wardrobe color** while skin and eyes remain true-to-life; background kept in controlled neutral midtones for separation; neutral white balance; neutral shadows; preserve fabric texture in highlights and blacks).\n   (f·1) **Wardrobe primary color & dye/finish (choose ONE pair and state it explicitly in the sentence):**\n        • deep jewel tone = {emerald, cobalt, crimson, royal purple} with **ink-dyed / matte weave**; OR\n        • inky dark = {obsidian black, charcoal graphite, midnight navy} with **satin sheen / tightly woven twill**.\n7) Append ALL of these phrases verbatim in the body as a final technical tag block at the end of the sentence, in this exact order and punctuation, unchanged: “curvy, captured in motion, masterpiece, best quality, highres, absurdres, daylight WB (~6500K), expose for wardrobe to preserve highlight detail, protect deep blacks from crush, preserve fabric texture in deep blacks and highlights, bright rim light on silhouette, soft diffused key light on face, gentle highlight roll-off, chiaroscuro, vivid colors with rich saturation concentrated in wardrobe, background in controlled neutral midtones, clean white point with neutral gray-card reference, cinematic vivid grading”\n8) Before the technical tag block, integrate concise dynamism cues (adapt naturally, not verbatim): shallow depth of field, graceful mid-motion capture, twisting torso and flowing gesture, windswept hair and fluttering fabric, while the face stays softly lit.\n9) Do not contradict yourself. If conflicts arise, prioritize vivid wardrobe color, preserved fabric texture, and natural-eye rendering.\n10) Keep the output as a single grammatically correct English sentence, professional tone. No extra commentary, bullets, or quotation marks.\n"],"color":"#432","bgcolor":"#653"},{"id":102,"type":"Note","pos":[1700,-2420],"size":[870,420],"flags":{},"order":25,"mode":0,"inputs":[],"outputs":[],"properties":{"ue_properties":{"widget_ue_connectable":{},"version":"7.1","input_ue_unconnectable":{}}},"widgets_values":["You are a prompt writer. Produce ONE single-line, high-artistic, soul-stirring prompt for a NoobAI (SDXL) image generator. Output exactly one sentence with no line breaks; target 80–130 words, hard limit 150 words.\n\nRules (follow strictly):\n\n1) Do NOT reference any provided image’s style, artists, or brands. No negative prompt syntax. Avoid any pastel, muted, flat, faded, grayish, or sepia wording.\n2) The prompt MUST start with: “questionable, a modern seinen flat color anime coloring illustration of …”\n3) Always cast the SAME NUMBER of characters as in the reference image and keep genders identical (e.g., one male + one female → output must be one male + one female). Do not add or remove characters.\n4) All leads must be ADULT Japanese, Chinese, or Taiwanese characters (20+). Explicitly indicate adult age (e.g., “in her mid-20s”). The tone must be mature, sensual, and suggestive (tasteful, a bit questionable). Prohibit any teen/underage wording.\n5) Vividly describe each character’s facial expression with nuance (eyes, mouth, micro-expressions, and attitude). For the eyes, portray natural dark-brown or black irises with a subtle limbal ring, soft white catchlights, neutral sclera, fine eyelashes, and realistic specular highlights; emphasize lifelike moisture and micro-reflections from the environment while keeping the eyes matte and non-luminous.\n6) Maintain this content order in one sentence:\n   (a) cast and ages with exact count and genders matching the reference,\n   (b) facial expressions with the natural-eye rendering above,\n   (c) motion/pose and attire, with elegant s-curve posture and pronounced hourglass proportions, defined waist-to-hip ratio, full bust with natural weight and lift, taut abdomen, rounded hips and thighs, long leg line with clean ankle taper, plus form-fitting fabric whose micro-folds and highlight seams discreetly trace the curves,\n   (d) choose exactly ONE background—“modern city street” OR “a contemporary office with floor-to-ceiling windows” OR “grocery store” OR “classroom”—whichever logically fits the action/subject,\n   (e) camera/composition (portrait lens ~85mm, eye-level or slightly low angle if needed, slightly off-center composition with centered focus priority and gentle edge falloff, elegant motion framing, perspective compression, strong leading lines where available),\n   (f) lighting (soft diffused key light on the face; bright rim light along silhouette and flowing fabric; chiaroscuro with punchy contrast),\n   (g) color and grading (concentrate vivid colors, rich saturation, and bold chroma in wardrobe and background while maintaining true-to-life skin and eye tones; neutral white balance but vivid saturation; avoid muted or flat colors).\n7) Append ALL of these phrases verbatim in the body as a final technical tag block at the end of the sentence, in this exact order and punctuation, unchanged: “curvy, captured in motion, masterpiece, best quality, amazing quality, highres, absurdres, depth of field: shallow, daylight white balance (~6500K), soft diffused key light on face, bright rim light on silhouette, gentle highlight roll-off, chiaroscuro, high contrast, punchy contrast with vibrant tones, vivid colors with rich saturation and bold chroma focused on wardrobe and background, clean white point with neutral gray-card reference, cinematic vivid grading, HDR vivid look”\n8) Before the technical tag block, integrate concise dynamism cues (adapt naturally, not verbatim): shallow depth of field with creamy background bokeh, off-center framing, graceful mid-motion capture, twisting torso and flowing gesture, windswept hair and fluttering fabric, background panning blur or subtle radial streaks, foreground occluders for parallax, subtle motion blur on limbs (shutter-drag feel), bright rim light carving the silhouette while the face stays softly lit.\n9) Do not contradict yourself (e.g., do not pair “desaturated” with “rich saturation”). If conflicts arise, prioritize vivid/saturated/colorful directives and the natural-eye rendering requirements. Redundancy restrictions do not apply to the verbatim technical tag block in Rule 7.\n10) Keep the output as a single grammatically correct English sentence, professional tone. No extra commentary, bullets, or quotation marks.\n"],"color":"#432","bgcolor":"#653"},{"id":121,"type":"Note","pos":[2030,-1000],"size":[850,120],"flags":{},"order":26,"mode":0,"inputs":[],"outputs":[],"properties":{"ue_properties":{"widget_ue_connectable":{},"version":"7.1","input_ue_unconnectable":{}}},"widgets_values":[", photorealistic, realistic, 3d, photography\n"],"color":"#432","bgcolor":"#653"},{"id":88,"type":"PrimitiveStringMultiline","pos":[1740,-1260],"size":[850,200],"flags":{},"order":27,"mode":0,"inputs":[],"outputs":[{"name":"STRING","type":"STRING","links":[613]}],"properties":{"cnr_id":"comfy-core","ver":"0.3.57","Node name for S&R":"PrimitiveStringMultiline","ue_properties":{"widget_ue_connectable":{"value":true},"version":"7.1","input_ue_unconnectable":{}}},"widgets_values":["warm tones, yellow cast, chibi, super-deformed, big head, huge eyes, baby face, childish, cute, kawaii, moe, cartoony, deformed anatomy, blur, lowres, bad anatomy, extra limbs, disfigured, poorly drawn, deformed, low quality, monochrome, text, watermark, signature, oversaturated, underexposed, overexposed, noise, artifacts, worst quality,normal quality, anatomical nonsense, bad anatomy, interlocked fingers, extra fingers, watermark, simple background, transparent, low quality, logo, signature, glowing eyes, red eyes, luminescent eyes, neon eyes, emissive eyes, laser eyes, photorealistic, realistic, 3d, photography"]},{"id":107,"type":"FaceDetailer","pos":[2480,-230],"size":[400,960],"flags":{},"order":54,"mode":0,"inputs":[{"name":"image","type":"IMAGE","link":2449},{"name":"model","type":"MODEL","link":2474},{"name":"clip","type":"CLIP","link":null},{"name":"vae","type":"VAE","link":null},{"name":"positive","type":"CONDITIONING","link":2464},{"name":"negative","type":"CONDITIONING","link":2465},{"name":"bbox_detector","type":"BBOX_DETECTOR","link":2455},{"name":"sam_model_opt","shape":7,"type":"SAM_MODEL","link":null},{"name":"segm_detector_opt","shape":7,"type":"SEGM_DETECTOR","link":2743},{"name":"detailer_hook","shape":7,"type":"DETAILER_HOOK","link":null},{"name":"scheduler_func_opt","shape":7,"type":"SCHEDULER_FUNC","link":null}],"outputs":[{"name":"image","type":"IMAGE","links":[2458,2874]},{"name":"cropped_refined","shape":6,"type":"IMAGE","links":null},{"name":"cropped_enhanced_alpha","shape":6,"type":"IMAGE","links":null},{"name":"mask","type":"MASK","links":null},{"name":"detailer_pipe","type":"DETAILER_PIPE","links":null},{"name":"cnet_images","shape":6,"type":"IMAGE","links":null}],"properties":{"cnr_id":"comfyui-impact-pack","ver":"cb0655f9a11ad771b4f6a846f08be29b5b66f0eb","Node name for S&R":"FaceDetailer","ue_properties":{"widget_ue_connectable":{"guide_size":true,"guide_size_for":true,"max_size":true,"seed":true,"steps":true,"cfg":true,"sampler_name":true,"scheduler":true,"denoise":true,"feather":true,"noise_mask":true,"force_inpaint":true,"bbox_threshold":true,"bbox_dilation":true,"bbox_crop_factor":true,"sam_detection_hint":true,"sam_dilation":true,"sam_threshold":true,"sam_bbox_expansion":true,"sam_mask_hint_threshold":true,"sam_mask_hint_use_negative":true,"drop_size":true,"wildcard":true,"cycle":true,"inpaint_model":true,"noise_mask_feather":true,"tiled_encode":true,"tiled_decode":true},"version":"7.1","input_ue_unconnectable":{}}},"widgets_values":[1024,true,64,751845859945643,"randomize",20,5,"dpmpp_2m","karras",0.35,16,true,true,0.7,10,2.5,"center-1",0,0.9,0,0.7,"False",10,"",1,false,20,false,false]},{"id":10,"type":"KSamplerAdvanced","pos":[1720,-190],"size":[300,334],"flags":{},"order":50,"mode":0,"inputs":[{"name":"model","type":"MODEL","link":null},{"name":"positive","type":"CONDITIONING","link":488},{"name":"negative","type":"CONDITIONING","link":489},{"name":"latent_image","type":"LATENT","link":27}],"outputs":[{"name":"LATENT","type":"LATENT","slot_index":0,"links":[13,2776]}],"title":"KSampler (Advanced) - BASE","properties":{"cnr_id":"comfy-core","ver":"0.3.33","Node name for S&R":"KSamplerAdvanced","ue_properties":{"widget_ue_connectable":{"steps":true,"end_at_step":true},"version":"7.0.1"}},"widgets_values":["enable",896679759090698,"randomize",30,5.5,"euler","simple",0,30,"enable"]},{"id":83,"type":"ControlNetApplyAdvanced","pos":[1350,-200],"size":[270,186],"flags":{},"order":48,"mode":0,"inputs":[{"name":"positive","type":"CONDITIONING","link":486},{"name":"negative","type":"CONDITIONING","link":487},{"name":"control_net","type":"CONTROL_NET","link":475},{"name":"image","type":"IMAGE","link":2330},{"name":"vae","shape":7,"type":"VAE","link":null}],"outputs":[{"name":"positive","type":"CONDITIONING","links":[488,2464]},{"name":"negative","type":"CONDITIONING","links":[489,2465]}],"properties":{"cnr_id":"comfy-core","ver":"0.3.57","Node name for S&R":"ControlNetApplyAdvanced","ue_properties":{"widget_ue_connectable":{"strength":true,"start_percent":true,"end_percent":true},"version":"7.1","input_ue_unconnectable":{}}},"widgets_values":[1,0,0.35]},{"id":65,"type":"ControlNetApplyAdvanced","pos":[960,-220],"size":[270,186],"flags":{},"order":44,"mode":0,"inputs":[{"name":"positive","type":"CONDITIONING","link":75},{"name":"negative","type":"CONDITIONING","link":76},{"name":"control_net","type":"CONTROL_NET","link":268},{"name":"image","type":"IMAGE","link":467},{"name":"vae","shape":7,"type":"VAE","link":null}],"outputs":[{"name":"positive","type":"CONDITIONING","links":[486]},{"name":"negative","type":"CONDITIONING","links":[487]}],"properties":{"cnr_id":"comfy-core","ver":"0.3.57","Node name for S&R":"ControlNetApplyAdvanced","ue_properties":{"widget_ue_connectable":{"strength":true,"start_percent":true,"end_percent":true},"version":"7.1","input_ue_unconnectable":{}}},"widgets_values":[1,0,0.29]},{"id":105,"type":"PrimitiveStringMultiline","pos":[-1560,-2300],"size":[1070,670],"flags":{},"order":28,"mode":0,"inputs":[],"outputs":[{"name":"STRING","type":"STRING","links":[2433]}],"properties":{"cnr_id":"comfy-core","ver":"0.3.57","Node name for S&R":"PrimitiveStringMultiline","ue_properties":{"widget_ue_connectable":{"value":true},"version":"7.1","input_ue_unconnectable":{}}},"widgets_values":["You are a prompt writer. Produce ONE single-line, high-artistic, soul-stirring prompt for a NoobAI (IllustriousXL) image generator. Output exactly one sentence with no line breaks; target 80–130 words, hard limit 150 words.\n\nRules (follow strictly):\n\n1) Do NOT reference any provided image’s style, artists, or brands. No negative prompt syntax.\n2) The prompt MUST start with: “a modern seinen anime coloring flat color illustration of …”\n3) Always cast the SAME NUMBER of characters as in the reference image and keep genders identical (e.g., one male + one female → output must be one male + one female). Do not add or remove characters.\n4) All leads must be ADULT Japanese, Korean, or Taiwanese characters (20+). Explicitly indicate adult age (e.g., “in her mid-20s”). The tone must be mature, sensual, and suggestive (tasteful, a bit questionable).\n5) Vividly describe each character’s facial expression with nuance (eyes, mouth, micro-expressions, and attitude). For the eyes, portray natural dark-brown or black irises with a subtle limbal ring, soft catchlights, neutral sclera, fine eyelashes, and realistic specular highlights; emphasize lifelike moisture and micro-reflections from the environment while keeping the eyes matte and non-luminous.\n6) Maintain this content order in one sentence:\n   (a) cast and ages with exact count and genders matching the reference,\n   (b) facial expressions with the natural-eye rendering above,\n   (c) motion/pose and attire, with elegant s-curve posture, defined waist-to-hip ratio, full bust with natural weight and lift, taut abdomen, rounded hips and thighs, long leg line with clean ankle taper,\n   (d) choose exactly ONE background—“modern city street” OR “a contemporary office” OR “grocery wild club” OR “living room”, whichever logically fits the action/subject,\n   (e) color and grading (**prioritize vivid wardrobe color** while skin and eyes remain true-to-life; background kept in controlled neutral midtones for separation; neutral white balance; neutral shadows; preserve fabric texture in highlights and blacks).\n   (e·1) **Wardrobe primary color & dye/finish (choose ONE pair and state it explicitly in the sentence):**\n        • deep jewel tone = {emerald, cobalt, crimson, royal purple} with **ink-dyed / matte weave**; OR\n        • inky dark = {obsidian black, charcoal graphite, midnight navy} with **satin sheen / tightly woven twill**.\n7) Append ALL of these phrases verbatim in the body as a final technical tag block at the end of the sentence, in this exact order and punctuation, unchanged: “curvy, captured in motion, masterpiece, best quality, highres, absurdres, daylight WB (~6500K), expose for wardrobe to preserve highlight detail, protect deep blacks from crush, preserve fabric texture in deep blacks and highlights, bright rim light on silhouette, soft diffused key light on face, gentle highlight roll-off, chiaroscuro, vivid colors with rich saturation concentrated in wardrobe, background in controlled neutral midtones, clean white point with neutral gray-card reference, cinematic vivid grading”\n8) Before the technical tag block, integrate concise dynamism cues (adapt naturally, not verbatim): shallow depth of field, graceful mid-motion capture, twisting torso and flowing gesture, windswept hair and fluttering fabric, while the face stays softly lit.\n9) Do not contradict yourself. If conflicts arise, prioritize vivid wardrobe color, preserved fabric texture, and natural-eye rendering.\n10) Keep the output as a single grammatically correct English sentence, professional tone. No extra commentary, bullets, or quotation marks.\n"]},{"id":77,"type":"ImageResize+","pos":[-560,-840],"size":[270,218],"flags":{},"order":32,"mode":0,"inputs":[{"name":"image","type":"IMAGE","link":1024}],"outputs":[{"name":"IMAGE","type":"IMAGE","links":[1003,1004,2702]},{"name":"width","type":"INT","links":[156]},{"name":"height","type":"INT","links":[157]}],"properties":{"cnr_id":"comfyui_essentials","ver":"9d9f4bedfc9f0321c19faf71855e228c93bd0dc9","Node name for S&R":"ImageResize+","ue_properties":{"widget_ue_connectable":{"width":true,"height":true,"interpolation":true,"method":true,"condition":true,"multiple_of":true},"version":"7.1","input_ue_unconnectable":{}}},"widgets_values":[1644,1728,"nearest","keep proportion","always",16]},{"id":4,"type":"CheckpointLoaderSimple","pos":[130,-1160],"size":[480,100],"flags":{},"order":29,"mode":0,"inputs":[],"outputs":[{"name":"MODEL","type":"MODEL","slot_index":0,"links":[2209]},{"name":"CLIP","type":"CLIP","slot_index":1,"links":[61]},{"name":"VAE","type":"VAE","slot_index":2,"links":[62]}],"title":"Load Checkpoint - BASE","properties":{"cnr_id":"comfy-core","ver":"0.3.33","Node name for S&R":"CheckpointLoaderSimple","models":[{"name":"sd_xl_base_1.0.safetensors","url":"https://huggingface.co/stabilityai/stable-diffusion-xl-base-1.0/resolve/main/sd_xl_base_1.0.safetensors?download=true","directory":"checkpoints"}],"ue_properties":{"widget_ue_connectable":{},"version":"7.0.1"}},"widgets_values":["noob/oneObsessionBranch_v6MatureEPS.safetensors"],"color":"#2a363b","bgcolor":"#3f5159"},{"id":19,"type":"SaveImage","pos":[-1910,-1520],"size":[790,900],"flags":{},"order":35,"mode":0,"inputs":[{"name":"images","type":"IMAGE","link":2701}],"outputs":[],"properties":{"cnr_id":"comfy-core","ver":"0.3.33","Node name for S&R":"SaveImage","ue_properties":{"widget_ue_connectable":{},"version":"7.0.1"}},"widgets_values":["oneobs"]}],"links":[[13,10,0,11,3,"LATENT"],[14,12,0,11,0,"MODEL"],[27,5,0,10,3,"LATENT"],[59,61,0,63,0,"STRING"],[61,4,1,64,1,"CLIP"],[62,4,2,64,2,"VAE"],[75,6,0,65,0,"CONDITIONING"],[76,7,0,65,1,"CONDITIONING"],[115,70,0,11,5,"INT"],[116,71,0,11,6,"INT"],[156,77,1,5,0,"INT"],[157,77,2,5,1,"INT"],[244,61,0,81,0,"*"],[268,66,0,65,2,"CONTROL_NET"],[467,73,0,65,3,"IMAGE"],[475,84,0,83,2,"CONTROL_NET"],[486,65,0,83,0,"CONDITIONING"],[487,65,1,83,1,"CONDITIONING"],[488,83,0,10,1,"CONDITIONING"],[489,83,1,10,2,"CONDITIONING"],[613,88,0,86,0,"*"],[614,89,0,16,1,"STRING"],[615,90,0,15,1,"STRING"],[616,91,0,7,1,"STRING"],[617,92,0,6,1,"STRING"],[649,16,0,11,2,"CONDITIONING"],[650,15,0,11,1,"CONDITIONING"],[651,12,1,16,0,"CLIP"],[652,12,1,15,0,"CLIP"],[1003,77,0,61,0,"IMAGE"],[1004,77,0,97,0,"*"],[1014,98,0,73,0,"IMAGE"],[1024,75,0,77,0,"IMAGE"],[1313,71,0,11,4,"INT"],[2113,101,0,61,2,"STRING"],[2209,4,0,104,0,"MODEL"],[2330,78,0,83,3,"IMAGE"],[2336,98,0,78,0,"IMAGE"],[2433,105,0,61,1,"STRING"],[2449,17,0,107,0,"IMAGE"],[2455,108,0,107,6,"BBOX_DETECTOR"],[2458,107,0,94,0,"IMAGE"],[2464,83,0,107,4,"CONDITIONING"],[2465,83,1,107,5,"CONDITIONING"],[2474,110,0,107,1,"MODEL"],[2539,104,0,111,0,"MODEL"],[2701,95,0,19,0,"IMAGE"],[2702,77,0,112,0,"IMAGE"],[2743,108,1,107,8,"SEGM_DETECTOR"],[2776,10,0,17,0,"LATENT"],[2873,17,0,116,0,"IMAGE"],[2874,107,0,116,1,"IMAGE"],[3136,111,0,117,0,"MODEL"],[3137,117,0,64,0,"MODEL"]],"groups":[],"config":{},"extra":{"ds":{"scale":0.7247295000000497,"offset":[2542.9387079843323,1718.3051924540953]},"frontendVersion":"1.28.5","ue_links":[{"downstream":7,"downstream_slot":0,"upstream":"4","upstream_slot":1,"controller":64,"type":"CLIP"},{"downstream":6,"downstream_slot":0,"upstream":"4","upstream_slot":1,"controller":64,"type":"CLIP"},{"downstream":17,"downstream_slot":1,"upstream":"4","upstream_slot":2,"controller":64,"type":"VAE"},{"downstream":110,"downstream_slot":0,"upstream":"4","upstream_slot":0,"controller":64,"type":"MODEL"},{"downstream":107,"downstream_slot":2,"upstream":"4","upstream_slot":1,"controller":64,"type":"CLIP"},{"downstream":107,"downstream_slot":3,"upstream":"4","upstream_slot":2,"controller":64,"type":"VAE"},{"downstream":10,"downstream_slot":0,"upstream":"4","upstream_slot":0,"controller":64,"type":"MODEL"},{"downstream":83,"downstream_slot":4,"upstream":"4","upstream_slot":2,"controller":64,"type":"VAE"},{"downstream":65,"downstream_slot":4,"upstream":"4","upstream_slot":2,"controller":64,"type":"VAE"}],"links_added_by_ue":[4947,4948,4949,4950,4951,4952,4953,4954,4955],"VHS_latentpreview":false,"VHS_latentpreviewrate":1,"VHS_MetadataImage":true,"VHS_KeepIntermediate":true},"version":0.4}